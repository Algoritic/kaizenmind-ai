from typing import List, Dict, Any
import logging
from pentestai.config import RuntimeConfig, setup_logging
from pentestai.tools.llm_adapter import OllamaLLM, OpenAIAdapter
from pentestai.langgraph_graphs.review_graph import build_review_graph
from pentestai.utils.file_store import FileStore
from pentestai.report.generator import write_outputs

logger = logging.getLogger(__name__)

try:
    from pentestai.langgraph_graphs.external_langgraph_agent import build_external_graph
    HAVE_EXTERNAL_GRAPH = True
except Exception:
    HAVE_EXTERNAL_GRAPH = False

def _make_llm(cfg: RuntimeConfig):
    if cfg.llm.backend == "ollama":
        return OllamaLLM(cfg.llm.ollama_url, cfg.llm.ollama_model)
    elif cfg.llm.backend == "openai" and cfg.llm.openai_api_base and cfg.llm.openai_api_key:
        # You can choose a default model name here if you like (e.g., "gpt-4o-mini")
        return OpenAIAdapter(cfg.llm.openai_api_base, cfg.llm.openai_api_key, "gpt-4o-mini")
    return None

def run_pipeline(repo_path: str | None = None, apk_path: str | None = None, run_id: str | None = None) -> Dict[str, Any]:
    cfg = RuntimeConfig()
    setup_logging(cfg.logging)
    store = FileStore(cfg.workdir)
    run_id = run_id or store.run_id()

    llm = _make_llm(cfg)
    logger.info(f"LLM backend: {cfg.llm.backend}; use_langgraph={cfg.use_langgraph}; external_graph={'yes' if HAVE_EXTERNAL_GRAPH else 'no'}")

    if cfg.use_langgraph and HAVE_EXTERNAL_GRAPH:
        graph = build_external_graph(llm)
    else:
        graph = build_review_graph()  # regex/static only

    initial_state = {"repo_path": repo_path, "apk_path": apk_path, "plan": {}, "results": [], "artifacts": {}}
    final = graph.invoke(initial_state)

    # Normalize results into sections
    sections: List[Dict[str, Any]] = []
    for r in final.get("results", []):
        secs = []
        for f in r.get("findings", []):
            secs.append({
                "title": f.get("title", ""),
                "severity": f.get("severity", "low"),
                "description": f.get("description", ""),
                "file": f.get("file"),
                "line": f.get("line"),
                "recommendation": f.get("recommendation"),
            })
        sections.append({"title": r.get("title", "Section"), "findings": secs})

    # Summarize severities
    severities = {"critical": 0, "high": 0, "medium": 0, "low": 0}
    for s in sections:
        for f in s["findings"]:
            sev = f.get("severity", "low")
            if sev in severities:
                severities[sev] += 1

    report = {
        "project": repo_path or apk_path or "n/a",
        "id": run_id,
        "summary": severities,
        "sections": sections,
        "artifacts": final.get("artifacts", {}),
        "metadata": {"plan": final.get("plan", {})},
    }

    j, h = write_outputs(report, store.root)
    logger.info(f"Pentest pipeline finished. Report generated: {j}")
    return {"report_json": j, "report_html": h, "run_id": run_id, "report": report}
